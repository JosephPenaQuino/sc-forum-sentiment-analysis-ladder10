{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental Analysis of Starcraft 2 new patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting reviews from their forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_R_PATH = 'r.txt' # file where it is saved sc2 data\n",
    "URL = 'https://us.forums.blizzard.com/en/starcraft/t/new-ladder-season-incoming/2577'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if r.txt exists, if not download it\n",
    "if os.path.exists('r.txt'):\n",
    "    with open(FILE_R_PATH, 'r') as f:\n",
    "        r_text = f.read()\n",
    "else:\n",
    "    r = requests.get(URL)\n",
    "    print(r.status_code)\n",
    "    r_text = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse data\n",
    "soup  = BeautifulSoup(r_text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs = soup.findAll(class_='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for div in divs:\n",
    "    pagraphs = div.findAll('p')\n",
    "    paragraph = '\\n'.join([p.text for p in pagraphs])\n",
    "    reviews.append(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(reviews), columns=['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's how many words do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] =  df['review'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many characters do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['char_count'] = df['review'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['char_count'] == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average length of words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_words(x):\n",
    "    words = x.split()\n",
    "    big_sum = sum(len(word) for word in words) \n",
    "    if big_sum == 0:\n",
    "        return 0\n",
    "    return big_sum / len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['average_word_length'] = df['review'].apply(lambda x: average_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/joseph/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stopwords_count'] = df['review'].apply(lambda x: len([word for word in x.split() if word.lower() in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stopword_rate'] = df['stopwords_count'] / df['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>stopword_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ASL12 maps GOGOGO!!!</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cydra go Marry me!</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Super genial. Desde Huancayo Per√∫ estamos supe...</td>\n",
       "      <td>14</td>\n",
       "      <td>84</td>\n",
       "      <td>5.071429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nice. Very good. Saludos desde Argentina</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>very happy happy happy</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What abour 2vs2 ranked??</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Would be interested in chatting with someone r...</td>\n",
       "      <td>14</td>\n",
       "      <td>107</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>4</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Beautiful news!! peruvian fans was expecting a...</td>\n",
       "      <td>12</td>\n",
       "      <td>73</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Please use the ASL map pool. You can maybe add...</td>\n",
       "      <td>33</td>\n",
       "      <td>189</td>\n",
       "      <td>4.757576</td>\n",
       "      <td>11</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Big thanks!! A thought maybe more map in map p...</td>\n",
       "      <td>26</td>\n",
       "      <td>134</td>\n",
       "      <td>4.192308</td>\n",
       "      <td>9</td>\n",
       "      <td>0.346154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greetings,\\nLadder Season 10 is coming for Sta...</td>\n",
       "      <td>44</td>\n",
       "      <td>236</td>\n",
       "      <td>4.386364</td>\n",
       "      <td>16</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>we hope some day to see 2v2 ladder!</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@gebz\\nAs much as I‚Äôd like to beat a dead hors...</td>\n",
       "      <td>42</td>\n",
       "      <td>202</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>18</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>It would be great if you can use a map pool fr...</td>\n",
       "      <td>28</td>\n",
       "      <td>154</td>\n",
       "      <td>4.535714</td>\n",
       "      <td>12</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you guys for such a quick reaction! &lt;3</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>My biggest piece of feedback is that more comm...</td>\n",
       "      <td>142</td>\n",
       "      <td>796</td>\n",
       "      <td>4.591549</td>\n",
       "      <td>64</td>\n",
       "      <td>0.450704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you for doing this. It‚Äôs really importan...</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>5</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hello, what about 2v2 Ladder?\\nThanks for all</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>About time. So lazy.</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  word_count  char_count  \\\n",
       "16                               ASL12 maps GOGOGO!!!           3          20   \n",
       "6                                 Cydra go Marry me!            4          19   \n",
       "14  Super genial. Desde Huancayo Per√∫ estamos supe...          14          84   \n",
       "18           Nice. Very good. Saludos desde Argentina           6          40   \n",
       "4                              very happy happy happy           4          22   \n",
       "7                            What abour 2vs2 ranked??           4          24   \n",
       "3   Would be interested in chatting with someone r...          14         107   \n",
       "17  Beautiful news!! peruvian fans was expecting a...          12          73   \n",
       "12  Please use the ASL map pool. You can maybe add...          33         189   \n",
       "10  Big thanks!! A thought maybe more map in map p...          26         134   \n",
       "0   Greetings,\\nLadder Season 10 is coming for Sta...          44         236   \n",
       "15                we hope some day to see 2v2 ladder!           8          35   \n",
       "9   @gebz\\nAs much as I‚Äôd like to beat a dead hors...          42         202   \n",
       "11  It would be great if you can use a map pool fr...          28         154   \n",
       "2        Thank you guys for such a quick reaction! <3           9          44   \n",
       "19  My biggest piece of feedback is that more comm...         142         796   \n",
       "5   Thank you for doing this. It‚Äôs really importan...          11          61   \n",
       "13      Hello, what about 2v2 Ladder?\\nThanks for all           8          44   \n",
       "8                                About time. So lazy.           4          20   \n",
       "\n",
       "    average_word_length  stopwords_count  stopword_rate  \n",
       "16             6.000000                0       0.000000  \n",
       "6              3.750000                0       0.000000  \n",
       "14             5.071429                1       0.071429  \n",
       "18             5.833333                1       0.166667  \n",
       "4              4.750000                1       0.250000  \n",
       "7              5.250000                1       0.250000  \n",
       "3              6.714286                4       0.285714  \n",
       "17             5.083333                4       0.333333  \n",
       "12             4.757576               11       0.333333  \n",
       "10             4.192308                9       0.346154  \n",
       "0              4.386364               16       0.363636  \n",
       "15             3.500000                3       0.375000  \n",
       "9              3.833333               18       0.428571  \n",
       "11             4.535714               12       0.428571  \n",
       "2              4.000000                4       0.444444  \n",
       "19             4.591549               64       0.450704  \n",
       "5              4.636364                5       0.454545  \n",
       "13             4.625000                4       0.500000  \n",
       "8              4.250000                2       0.500000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='stopword_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>stopword_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.894737</td>\n",
       "      <td>121.263158</td>\n",
       "      <td>4.724242</td>\n",
       "      <td>8.421053</td>\n",
       "      <td>0.314848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31.867599</td>\n",
       "      <td>177.105067</td>\n",
       "      <td>0.809818</td>\n",
       "      <td>14.492587</td>\n",
       "      <td>0.157337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>4.221154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.346154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>5.077381</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.436508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>142.000000</td>\n",
       "      <td>796.000000</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_count  char_count  average_word_length  stopwords_count  \\\n",
       "count   19.000000   19.000000            19.000000        19.000000   \n",
       "mean    21.894737  121.263158             4.724242         8.421053   \n",
       "std     31.867599  177.105067             0.809818        14.492587   \n",
       "min      3.000000   19.000000             3.500000         0.000000   \n",
       "25%      5.000000   29.500000             4.221154         1.000000   \n",
       "50%     11.000000   61.000000             4.625000         4.000000   \n",
       "75%     27.000000  144.000000             5.077381        10.000000   \n",
       "max    142.000000  796.000000             6.714286        64.000000   \n",
       "\n",
       "       stopword_rate  \n",
       "count      19.000000  \n",
       "mean        0.314848  \n",
       "std         0.157337  \n",
       "min         0.000000  \n",
       "25%         0.250000  \n",
       "50%         0.346154  \n",
       "75%         0.436508  \n",
       "max         0.500000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text based data for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lowercase'] = df['review'].apply(lambda x: ' '.join(word.lower() for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['punctuation'] = df['lowercase'].str.replace('[^\\w\\s]','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stopwords'] = df['punctuation'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "map        7\n",
       "pool       6\n",
       "like       5\n",
       "season     4\n",
       "ladder     4\n",
       "scr        4\n",
       "team       3\n",
       "happy      3\n",
       "maps       3\n",
       "thank      3\n",
       "10         3\n",
       "longer     2\n",
       "maybe      2\n",
       "would      2\n",
       "thanks     2\n",
       "use        2\n",
       "asl        2\n",
       "time       2\n",
       "good       2\n",
       "go         2\n",
       "nice       2\n",
       "big        2\n",
       "someone    2\n",
       "desde      2\n",
       "working    2\n",
       "saludos    2\n",
       "please     2\n",
       "dont       2\n",
       "see        2\n",
       "well       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(' '.join(df['stopwords']).split()).value_counts()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_stop_words = ['src', 'maps', '10', 'use', 'asl', 'go', 'desde', 'asl12', 'gogogo', 'argentina', '2v2', 'cydra', 'go', '3', '2vs2', 'ranked', 'huancayo', 'per√∫', 'estamos', 'map', 'pool', 'starcraft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_review'] = df['stopwords'].apply(lambda x: ' '.join(word for word in x.split() if word not in other_stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_review_word_count'] = df['cleaned_review'].apply(lambda x: len(x.split()))\n",
    "df['clean_rate'] = df['cleaned_review_word_count'] / df['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>stopword_rate</th>\n",
       "      <th>lowercase</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>cleanreview</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>cleaned_review_word_count</th>\n",
       "      <th>clean_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greetings,\\nLadder Season 10 is coming for Sta...</td>\n",
       "      <td>44</td>\n",
       "      <td>236</td>\n",
       "      <td>4.386364</td>\n",
       "      <td>16</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>greetings, ladder season 10 is coming for star...</td>\n",
       "      <td>greetings ladder season 10 is coming for starc...</td>\n",
       "      <td>greetings ladder season 10 coming starcraft re...</td>\n",
       "      <td>greetings ladder season coming starcraft remas...</td>\n",
       "      <td>greetings ladder season coming remastered next...</td>\n",
       "      <td>greetings ladder season coming remastered next...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you guys for such a quick reaction! &lt;3</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>thank you guys for such a quick reaction! &lt;3</td>\n",
       "      <td>thank you guys for such a quick reaction 3</td>\n",
       "      <td>thank guys quick reaction 3</td>\n",
       "      <td>thank guys quick reaction 3</td>\n",
       "      <td>thank guys quick reaction</td>\n",
       "      <td>thank guys quick reaction</td>\n",
       "      <td>4</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Would be interested in chatting with someone r...</td>\n",
       "      <td>14</td>\n",
       "      <td>107</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>4</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>would be interested in chatting with someone r...</td>\n",
       "      <td>would be interested in chatting with someone r...</td>\n",
       "      <td>would interested chatting someone regarding fu...</td>\n",
       "      <td>would interested chatting someone regarding fu...</td>\n",
       "      <td>would interested chatting someone regarding fu...</td>\n",
       "      <td>would interested chatting someone regarding fu...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>very happy happy happy</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>very happy happy happy</td>\n",
       "      <td>very happy happy happy</td>\n",
       "      <td>happy happy happy</td>\n",
       "      <td>happy happy happy</td>\n",
       "      <td>happy happy happy</td>\n",
       "      <td>happy happy happy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you for doing this. It‚Äôs really importan...</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>5</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>thank you for doing this. it‚Äôs really importan...</td>\n",
       "      <td>thank you for doing this its really important ...</td>\n",
       "      <td>thank really important scene</td>\n",
       "      <td>thank really important scene</td>\n",
       "      <td>thank really important scene</td>\n",
       "      <td>thank really important scene</td>\n",
       "      <td>4</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  word_count  char_count  \\\n",
       "0  Greetings,\\nLadder Season 10 is coming for Sta...          44         236   \n",
       "2       Thank you guys for such a quick reaction! <3           9          44   \n",
       "3  Would be interested in chatting with someone r...          14         107   \n",
       "4                             very happy happy happy           4          22   \n",
       "5  Thank you for doing this. It‚Äôs really importan...          11          61   \n",
       "\n",
       "   average_word_length  stopwords_count  stopword_rate  \\\n",
       "0             4.386364               16       0.363636   \n",
       "2             4.000000                4       0.444444   \n",
       "3             6.714286                4       0.285714   \n",
       "4             4.750000                1       0.250000   \n",
       "5             4.636364                5       0.454545   \n",
       "\n",
       "                                           lowercase  \\\n",
       "0  greetings, ladder season 10 is coming for star...   \n",
       "2       thank you guys for such a quick reaction! <3   \n",
       "3  would be interested in chatting with someone r...   \n",
       "4                             very happy happy happy   \n",
       "5  thank you for doing this. it‚Äôs really importan...   \n",
       "\n",
       "                                         punctuation  \\\n",
       "0  greetings ladder season 10 is coming for starc...   \n",
       "2         thank you guys for such a quick reaction 3   \n",
       "3  would be interested in chatting with someone r...   \n",
       "4                             very happy happy happy   \n",
       "5  thank you for doing this its really important ...   \n",
       "\n",
       "                                           stopwords  \\\n",
       "0  greetings ladder season 10 coming starcraft re...   \n",
       "2                        thank guys quick reaction 3   \n",
       "3  would interested chatting someone regarding fu...   \n",
       "4                                  happy happy happy   \n",
       "5                       thank really important scene   \n",
       "\n",
       "                                        clean_review  \\\n",
       "0  greetings ladder season coming starcraft remas...   \n",
       "2                        thank guys quick reaction 3   \n",
       "3  would interested chatting someone regarding fu...   \n",
       "4                                  happy happy happy   \n",
       "5                       thank really important scene   \n",
       "\n",
       "                                         cleanreview  \\\n",
       "0  greetings ladder season coming remastered next...   \n",
       "2                          thank guys quick reaction   \n",
       "3  would interested chatting someone regarding fu...   \n",
       "4                                  happy happy happy   \n",
       "5                       thank really important scene   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  greetings ladder season coming remastered next...   \n",
       "2                          thank guys quick reaction   \n",
       "3  would interested chatting someone regarding fu...   \n",
       "4                                  happy happy happy   \n",
       "5                       thank really important scene   \n",
       "\n",
       "   cleaned_review_word_count  clean_rate  \n",
       "0                         22    0.500000  \n",
       "2                          4    0.444444  \n",
       "3                          8    0.571429  \n",
       "4                          3    0.750000  \n",
       "5                          4    0.363636  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/joseph/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/joseph/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/joseph/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     /home/joseph/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet_ic.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('wordnet_ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized'] = df['cleaned_review'].apply(lambda x: ' '.join(Word(word).lemmatize() for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cf1c5ca3fc9c48c6dc44a1c503f966deb6bc787c66fefb67595fed0d92b838c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dataScience2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
